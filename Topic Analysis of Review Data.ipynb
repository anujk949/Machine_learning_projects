{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Help a leading mobile brand understand the voice of the customer by analyzing the reviews of their product on Amazon and the topics that customers are talking about. You will perform topic modeling on specific parts of speech. Youâ€™ll finally interpret the emerging topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular mobile phone brand, Lenovo has launched their budget smartphone in the Indian market. The client wants to understand the VOC (voice of the customer) on the product. This will be useful to not just evaluate the current product, but to also get some direction for developing the product pipeline. The client is particularly interested in the different aspects that customers care about. Product reviews by customers on a leading e-commerce site should provide a good view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import gensim\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_word = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read the .csv file using Pandas. Take a look at the top few records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Good but need updates and improvements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Worst mobile i have bought ever, Battery is dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>when I will get my 10% cash back.... its alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The worst phone everThey have changed the last...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1             Good but need updates and improvements\n",
       "1          0  Worst mobile i have bought ever, Battery is dr...\n",
       "2          1  when I will get my 10% cash back.... its alrea...\n",
       "3          1                                               Good\n",
       "4          0  The worst phone everThey have changed the last..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'D:\\Simplilearn\\project\\NLP\\Project1\\K8 Reviews v0.2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Normalize casings for the review text and extract the text into a list for easier manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.review = data.review.apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data.review.apply(lambda x: re.sub(r'[^\\w\\s]','',x)) ## removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data.review.apply(lambda x: ' '.join([item for item in x.split(' ') if item not in stop_word]))# removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>good need updates improvements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>worst mobile bought ever battery draining like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>get 10 cash back already 15 january</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>worst phone everthey changed last phone proble...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1                     good need updates improvements\n",
       "1          0  worst mobile bought ever battery draining like...\n",
       "2          1                get 10 cash back already 15 january\n",
       "3          1                                               good\n",
       "4          0  worst phone everthey changed last phone proble..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.review.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worst mobile bought ever battery draining like hell backup 6 7 hours internet uses even put mobile idle getting dischargedthis biggest lie amazon  lenove expected making full saying battery 4000mah  booster charger fake takes least 4 5 hours fully chargeddont know lenovo survive making full usplease dont go else regret like'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tokenize the reviews using NLTKs word_tokenize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['good', 'need', 'updates', 'improvements']]\n"
     ]
    }
   ],
   "source": [
    "tokenized = list(sent_to_words(corpus))\n",
    "print(tokenized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Perform parts-of-speech tagging on each sentence using the NLTK POS tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_pos = [nltk.pos_tag(word) for word in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('good', 'JJ'), ('need', 'NN'), ('updates', 'NNS'), ('improvements', 'NNS')]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_pos[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. For the topic model, we should  want to include only nouns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find out all the POS tags that correspond to nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_tag = ['NNS','NN','NNP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Limit the data to only terms with these tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag = [[token[0] for token in sent if token[1] in noun_tag] for sent in corpus_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['need', 'updates', 'improvements'],\n",
       " ['mobile',\n",
       "  'hell',\n",
       "  'backup',\n",
       "  'hours',\n",
       "  'uses',\n",
       "  'lie',\n",
       "  'amazon',\n",
       "  'lenove',\n",
       "  'battery',\n",
       "  'mah',\n",
       "  'booster',\n",
       "  'charger',\n",
       "  'hours',\n",
       "  'lenovo',\n",
       "  'usplease',\n",
       "  'dont']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Lemmatize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Different forms of the terms need to be treated as one.\n",
    "\n",
    "* No need to provide POS tag to lemmatizer for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_tags = [[lemmatizer.lemmatize(word) for word in sent] for sent in pos_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['need', 'update', 'improvement'],\n",
       " ['mobile',\n",
       "  'hell',\n",
       "  'backup',\n",
       "  'hour',\n",
       "  'us',\n",
       "  'lie',\n",
       "  'amazon',\n",
       "  'lenove',\n",
       "  'battery',\n",
       "  'mah',\n",
       "  'booster',\n",
       "  'charger',\n",
       "  'hour',\n",
       "  'lenovo',\n",
       "  'usplease',\n",
       "  'dont']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_tags[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7. Remove stopwords and punctuation (if there are any). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## already removed stopwords and puntuation in point 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Create a topic model using LDA on the cleaned-up data with 12 topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print out the top terms for each topic.\n",
    "\n",
    "* What is the coherence of the model with the c_v metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(lemmatized_tags)\n",
    "texts = lemmatized_tags\n",
    "corpus = [id2word.doc2bow(text) for text in texts] #bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 2),\n",
       " (11, 1),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build lda model for 12 topics\n",
    "lda_model = gensim.models.LdaMulticore(corpus = corpus,\n",
    "                                      id2word=id2word,\n",
    "                                      num_topics=12,\n",
    "                                      random_state=50,\n",
    "                                      chunksize=100,\n",
    "                                      passes=10,per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.284*\"problem\" + 0.082*\"heating\" + 0.052*\"network\" + 0.051*\"charger\" + '\n",
      "  '0.030*\"handset\" + 0.027*\"turbo\" + 0.024*\"sim\" + 0.014*\"connectivity\" + '\n",
      "  '0.012*\"bill\" + 0.011*\"connection\"'),\n",
      " (1,\n",
      "  '0.047*\"phone\" + 0.037*\"device\" + 0.029*\"return\" + 0.029*\"day\" + '\n",
      "  '0.027*\"issue\" + 0.027*\"support\" + 0.025*\"amazon\" + 0.022*\"customer\" + '\n",
      "  '0.021*\"call\" + 0.020*\"lenovo\"'),\n",
      " (2,\n",
      "  '0.112*\"service\" + 0.074*\"delivery\" + 0.065*\"month\" + 0.054*\"amazon\" + '\n",
      "  '0.043*\"smartphone\" + 0.037*\"thanks\" + 0.031*\"center\" + 0.028*\"centre\" + '\n",
      "  '0.026*\"function\" + 0.023*\"class\"'),\n",
      " (3,\n",
      "  '0.431*\"product\" + 0.157*\"mobile\" + 0.029*\"buy\" + 0.025*\"awesome\" + '\n",
      "  '0.023*\"dont\" + 0.015*\"bit\" + 0.014*\"amazon\" + 0.013*\"piece\" + 0.009*\"plz\" + '\n",
      "  '0.008*\"cost\"'),\n",
      " (4,\n",
      "  '0.144*\"camera\" + 0.042*\"quality\" + 0.033*\"phone\" + 0.027*\"battery\" + '\n",
      "  '0.018*\"mode\" + 0.016*\"feature\" + 0.016*\"performance\" + 0.014*\"processor\" + '\n",
      "  '0.012*\"music\" + 0.011*\"game\"'),\n",
      " (5,\n",
      "  '0.143*\"price\" + 0.102*\"battery\" + 0.095*\"backup\" + 0.085*\"phone\" + '\n",
      "  '0.058*\"camera\" + 0.053*\"range\" + 0.033*\"everything\" + 0.023*\"good\" + '\n",
      "  '0.023*\"performance\" + 0.022*\"quality\"'),\n",
      " (6,\n",
      "  '0.106*\"money\" + 0.052*\"waste\" + 0.041*\"value\" + 0.037*\"hai\" + 0.036*\"glass\" '\n",
      "  '+ 0.032*\"screen\" + 0.022*\"cast\" + 0.021*\"gorilla\" + 0.014*\"ho\" + '\n",
      "  '0.013*\"contact\"'),\n",
      " (7,\n",
      "  '0.558*\"phone\" + 0.039*\"feature\" + 0.017*\"star\" + 0.017*\"budget\" + '\n",
      "  '0.012*\"use\" + 0.011*\"look\" + 0.011*\"model\" + 0.010*\"expectation\" + '\n",
      "  '0.010*\"buy\" + 0.010*\"box\"'),\n",
      " (8,\n",
      "  '0.107*\"battery\" + 0.095*\"hour\" + 0.093*\"charge\" + 0.083*\"day\" + 0.053*\"use\" '\n",
      "  '+ 0.041*\"time\" + 0.028*\"charger\" + 0.026*\"ok\" + 0.018*\"usage\" + '\n",
      "  '0.017*\"min\"'),\n",
      " (9,\n",
      "  '0.211*\"battery\" + 0.180*\"issue\" + 0.082*\"heat\" + 0.050*\"drain\" + '\n",
      "  '0.049*\"life\" + 0.036*\"superb\" + 0.023*\"excellent\" + 0.021*\"month\" + '\n",
      "  '0.019*\"network\" + 0.018*\"purchase\"'),\n",
      " (10,\n",
      "  '0.152*\"note\" + 0.075*\"lenovo\" + 0.060*\"performance\" + 0.040*\"phone\" + '\n",
      "  '0.033*\"software\" + 0.022*\"please\" + 0.021*\"system\" + 0.021*\"update\" + '\n",
      "  '0.012*\"thing\" + 0.010*\"power\"'),\n",
      " (11,\n",
      "  '0.085*\"time\" + 0.073*\"quality\" + 0.060*\"speaker\" + 0.045*\"call\" + '\n",
      "  '0.033*\"work\" + 0.033*\"display\" + 0.031*\"sound\" + 0.029*\"hang\" + '\n",
      "  '0.021*\"fast\" + 0.018*\"volume\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics()) # Print out the top terms for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence of the model :  0.4818381900203999\n"
     ]
    }
   ],
   "source": [
    "print('coherence of the model : ',\n",
    "      CoherenceModel(model=lda_model,texts=texts,dictionary=id2word,coherence='c_v').get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Analyze the topics through the business lens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Determine which of the topics can be combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we can combine some topics based on specification of device like battery, camera, etc\n",
    "\n",
    "a) topic '0' and '8' can be combine as 'negative feedback'.\n",
    "\n",
    "b) topic '5' and '6' can be combine as 'battery'.\n",
    "\n",
    "c) topic '7' and '11' can be combine as 'display'.\n",
    "\n",
    "d) camera is found in too many topics so we are ignoring it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Create a topic model using LDA with what you think is the optimal number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the coherence of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use grid search to find optimal numbers of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_data = [' '.join(word) for word in lemmatized_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,                        # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized = vectorizer.fit_transform(lemmatized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {'n_components': [2,3,4,5,6,7,8], 'learning_decay': [.5, .7, .9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation()\n",
    "model = GridSearchCV(lda,param_grid=search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={'learning_decay': [0.5, 0.7, 0.9],\n",
       "                         'n_components': [2, 3, 4, 5, 6, 7, 8]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 2}\n",
      "Best Log Likelihood Score:  -74073.43473645803\n",
      "Model Perplexity:  187.42102140611075\n"
     ]
    }
   ],
   "source": [
    "best_model = model.best_estimator_ # Best Model\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above grid search model shows that optimal number of topic is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## building model with number of topics two\n",
    "lda_model = gensim.models.LdaMulticore(corpus = corpus,\n",
    "                                      id2word=id2word,\n",
    "                                      num_topics=2,\n",
    "                                      random_state=50,\n",
    "                                      chunksize=100,\n",
    "                                      passes=10,\n",
    "                                       decay=0.7,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coherence of the model :  0.512284641443429\n"
     ]
    }
   ],
   "source": [
    "print('coherence of the model : ',\n",
    "      CoherenceModel(model=lda_model,texts=texts,dictionary=id2word,coherence='c_v').get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. The business should be able to interpret the topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Name each of the identified topics.\n",
    "There are two topics named as: 'positive review' and 'negative review'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a table with the topic name and the top 10 terms in each to present to the business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_terms = lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(topic):\n",
    "    terms = []\n",
    "    for term in topic:\n",
    "        terms.append(term.split('*\"')[1][:-1])\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic = pd.DataFrame()\n",
    "df_topic['negative topic'] = clear(topic=topic_terms[0][1].split(' + '))\n",
    "df_topic['positive topic'] = clear(topic=topic_terms[1][1].split(' + '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative topic</th>\n",
       "      <th>positive topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>camera</td>\n",
       "      <td>phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>battery</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phone</td>\n",
       "      <td>battery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem</td>\n",
       "      <td>issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quality</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>performance</td>\n",
       "      <td>lenovo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mobile</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>note</td>\n",
       "      <td>note</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>heating</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feature</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  negative topic positive topic\n",
       "0         camera          phone\n",
       "1        battery        product\n",
       "2          phone        battery\n",
       "3        problem          issue\n",
       "4        quality           time\n",
       "5    performance         lenovo\n",
       "6         mobile            day\n",
       "7           note           note\n",
       "8        heating          price\n",
       "9        feature          money"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we are using noun phrase for topic modeling and as we know the dataset is for sentiments analysis so we have to use adverbs and verbs for better prediction, along with this we can use bigram and tri-gram to improve over end result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
