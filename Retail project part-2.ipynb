{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam,RMSprop,SGD,Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>9863</td>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13261</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13106</td>\n",
       "      <td>1488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>6635</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  SchoolHoliday\n",
       "0      1          2  2015-06-30   5735        568     1      1            0              0\n",
       "1      2          2  2015-06-30   9863        877     1      1            0              0\n",
       "2      3          2  2015-06-30  13261       1072     1      1            0              1\n",
       "3      4          2  2015-06-30  13106       1488     1      1            0              0\n",
       "4      5          2  2015-06-30   6635        645     1      1            0              0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(r'D:\\Simplilearn\\project\\Artificial-Intelligence-Capstone-Project-Datasets-master\\Project 3-Retail-Datasets_data\\train_data.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('Date',axis=1,inplace=True)\n",
    "train_data.loc[train_data.StateHoliday==0,'StateHoliday'] = '0'\n",
    "labelencoder= LabelEncoder()\n",
    "train_data.StateHoliday = labelencoder.fit_transform(train_data['StateHoliday'])\n",
    "train_data =train_data[~train_data.isin([np.nan, np.inf, -np.inf]).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take 100 shops\n",
    "train_data = train_data[train_data.Store<=100]\n",
    "train_data = train_data[train_data.Open == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['Sales']\n",
    "x = train_data.drop(['Sales','Open'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.Customers = (x.Customers-x.Customers.mean())/x.Customers.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "x = std.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.70757208, -0.87819728, -0.48347562,  1.11359979, -0.02637594,\n",
       "        -0.47415697],\n",
       "       [-1.67299604, -0.87819728,  0.64160312,  1.11359979, -0.02637594,\n",
       "        -0.47415697],\n",
       "       [-1.63842   , -0.87819728,  1.35160427,  1.11359979, -0.02637594,\n",
       "         2.10900624],\n",
       "       ...,\n",
       "       [ 1.68088004, -0.29664439, -1.10245098, -0.89798868, -0.02637594,\n",
       "         2.10900624],\n",
       "       [ 1.71545608, -0.29664439, -0.05019287, -0.89798868, -0.02637594,\n",
       "         2.10900624],\n",
       "       [ 1.19681545, -0.87819728, -0.29778301, -0.89798868, 25.60857187,\n",
       "         2.10900624]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(np.array(x),np.array(y),random_state=42,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(layers.Dense(12, activation='relu', input_shape = (x_train.shape[1],)))\n",
    "model_1.add(layers.Dense(64, activation='relu'))\n",
    "model_1.add(layers.BatchNormalization())\n",
    "model_1.add(layers.Dense(128, activation='relu'))\n",
    "model_1.add(layers.Dense(64, activation='relu'))\n",
    "model_1.add(layers.BatchNormalization())\n",
    "model_1.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(layers.Dense(32, activation='elu', input_shape = (x_train.shape[1],)))\n",
    "model_1.add(layers.Dense(64, activation='elu'))\n",
    "model_1.add(layers.Dense(64, activation='elu'))\n",
    "model_1.add(layers.BatchNormalization())\n",
    "\n",
    "## block 2\n",
    "model_1.add(layers.Dense(128, activation='elu'))\n",
    "model_1.add(layers.Dense(128, activation='elu'))\n",
    "model_1.add(layers.BatchNormalization())\n",
    "\n",
    "## block 3\n",
    "model_1.add(layers.Dense(256, activation='elu'))\n",
    "model_1.add(layers.Dense(256, activation='elu'))\n",
    "model_1.add(layers.BatchNormalization())\n",
    "\n",
    "## block 4\n",
    "model_1.add(layers.Dense(128, activation='elu'))\n",
    "model_1.add(layers.Dense(128, activation='elu'))\n",
    "model_1.add(layers.BatchNormalization())\n",
    "\n",
    "## block 5\n",
    "model_1.add(layers.Dense(64, activation='elu'))\n",
    "model_1.add(layers.Dense(64, activation='elu'))\n",
    "model_1.add(layers.Dense(32, activation='elu'))\n",
    "model_1.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss='mse',\n",
    "              optimizer = Adam(learning_rate=0.001),\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:ModelCheckpoint mode <built-in function min> is unknown, fallback to auto mode.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "checkpoint = ModelCheckpoint('model_3.h5',\n",
    "                            monitor='loss',\n",
    "                            mode=min,\n",
    "                            save_best_only=True,\n",
    "                            verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss',\n",
    "                              patience=9,\n",
    "                              min_delta=0,\n",
    "                              restore_best_weights=True,\n",
    "                              verbose=1)\n",
    "\n",
    "Reduce_ler_rate = ReduceLROnPlateau(monitor='loss',\n",
    "                                   factor=0.2,\n",
    "                                   patience=3,\n",
    "                                   verbose=1,\n",
    "                                   min_delta=0.001)\n",
    "\n",
    "callback = [checkpoint,early_stopping,Reduce_ler_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2533/2552 [============================>.] - ETA: 0s - loss: 5013647.5000 - mae: 1547.0806\n",
      "Epoch 00001: loss improved from inf to 4993100.50000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 6s 2ms/step - loss: 4993100.5000 - mae: 1544.2448\n",
      "Epoch 2/100\n",
      "2549/2552 [============================>.] - ETA: 0s - loss: 2265282.5000 - mae: 1128.5344\n",
      "Epoch 00002: loss improved from 4993100.50000 to 2265431.00000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 7s 3ms/step - loss: 2265431.0000 - mae: 1128.5953\n",
      "Epoch 3/100\n",
      "2549/2552 [============================>.] - ETA: 0s - loss: 2113610.2500 - mae: 1085.0304\n",
      "Epoch 00003: loss improved from 2265431.00000 to 2113457.25000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 6s 2ms/step - loss: 2113457.2500 - mae: 1085.0244\n",
      "Epoch 4/100\n",
      "2532/2552 [============================>.] - ETA: 0s - loss: 2009976.8750 - mae: 1062.9116\n",
      "Epoch 00004: loss improved from 2113457.25000 to 2007149.12500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 6s 2ms/step - loss: 2007149.1250 - mae: 1062.4099\n",
      "Epoch 5/100\n",
      "2534/2552 [============================>.] - ETA: 0s - loss: 1939298.5000 - mae: 1044.5187\n",
      "Epoch 00005: loss improved from 2007149.12500 to 1938772.87500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 6s 2ms/step - loss: 1938772.8750 - mae: 1044.2867\n",
      "Epoch 6/100\n",
      "2546/2552 [============================>.] - ETA: 0s - loss: 1818278.1250 - mae: 1015.1184\n",
      "Epoch 00006: loss improved from 1938772.87500 to 1818570.37500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 6s 2ms/step - loss: 1818570.3750 - mae: 1015.2074\n",
      "Epoch 7/100\n",
      "2545/2552 [============================>.] - ETA: 0s - loss: 1768339.8750 - mae: 1003.3322\n",
      "Epoch 00007: loss improved from 1818570.37500 to 1769354.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 6s 2ms/step - loss: 1769354.7500 - mae: 1003.4941\n",
      "Epoch 8/100\n",
      "2550/2552 [============================>.] - ETA: 0s - loss: 1743862.5000 - mae: 996.6275\n",
      "Epoch 00008: loss improved from 1769354.75000 to 1744113.37500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 6s 2ms/step - loss: 1744113.3750 - mae: 996.7297\n",
      "Epoch 9/100\n",
      "2537/2552 [============================>.] - ETA: 0s - loss: 1720688.1250 - mae: 993.6805\n",
      "Epoch 00009: loss improved from 1744113.37500 to 1720504.00000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 6s 2ms/step - loss: 1720504.0000 - mae: 993.7119\n",
      "Epoch 10/100\n",
      "2529/2552 [============================>.] - ETA: 0s - loss: 1689817.5000 - mae: 984.0524\n",
      "Epoch 00010: loss improved from 1720504.00000 to 1689091.87500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 6s 2ms/step - loss: 1689091.8750 - mae: 984.0974\n",
      "Epoch 11/100\n",
      "2544/2552 [============================>.] - ETA: 0s - loss: 1664720.5000 - mae: 976.2271\n",
      "Epoch 00011: loss improved from 1689091.87500 to 1664051.62500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1664051.6250 - mae: 976.1064\n",
      "Epoch 12/100\n",
      "2545/2552 [============================>.] - ETA: 0s - loss: 1668474.2500 - mae: 975.7294\n",
      "Epoch 00012: loss did not improve from 1664051.62500\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1668112.3750 - mae: 975.6130\n",
      "Epoch 13/100\n",
      "2543/2552 [============================>.] - ETA: 0s - loss: 1629180.0000 - mae: 963.3779\n",
      "Epoch 00013: loss improved from 1664051.62500 to 1629024.62500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 1629024.6250 - mae: 963.2981\n",
      "Epoch 14/100\n",
      "2543/2552 [============================>.] - ETA: 0s - loss: 1631111.0000 - mae: 963.6005\n",
      "Epoch 00014: loss did not improve from 1629024.62500\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 1631589.5000 - mae: 963.8180\n",
      "Epoch 15/100\n",
      "2543/2552 [============================>.] - ETA: 0s - loss: 1605999.7500 - mae: 953.3755\n",
      "Epoch 00015: loss improved from 1629024.62500 to 1607970.12500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 1607970.1250 - mae: 953.9637\n",
      "Epoch 16/100\n",
      "2539/2552 [============================>.] - ETA: 0s - loss: 1596930.8750 - mae: 951.8800\n",
      "Epoch 00016: loss improved from 1607970.12500 to 1596381.62500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1596381.6250 - mae: 951.9140\n",
      "Epoch 17/100\n",
      "2543/2552 [============================>.] - ETA: 0s - loss: 1579180.6250 - mae: 946.7383\n",
      "Epoch 00017: loss improved from 1596381.62500 to 1578179.25000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1578179.2500 - mae: 946.4680\n",
      "Epoch 18/100\n",
      "2549/2552 [============================>.] - ETA: 0s - loss: 1571886.5000 - mae: 943.2127\n",
      "Epoch 00018: loss improved from 1578179.25000 to 1571846.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 1571846.7500 - mae: 943.2587\n",
      "Epoch 19/100\n",
      "2549/2552 [============================>.] - ETA: 0s - loss: 1564267.5000 - mae: 937.7986\n",
      "Epoch 00019: loss improved from 1571846.75000 to 1564332.50000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1564332.5000 - mae: 937.8486\n",
      "Epoch 20/100\n",
      "2541/2552 [============================>.] - ETA: 0s - loss: 1534336.6250 - mae: 929.7964\n",
      "Epoch 00020: loss improved from 1564332.50000 to 1534787.25000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1534787.2500 - mae: 929.8621\n",
      "Epoch 21/100\n",
      "2541/2552 [============================>.] - ETA: 0s - loss: 1547873.6250 - mae: 932.8358\n",
      "Epoch 00021: loss did not improve from 1534787.25000\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1547602.7500 - mae: 932.9399\n",
      "Epoch 22/100\n",
      "2551/2552 [============================>.] - ETA: 0s - loss: 1513923.3750 - mae: 919.1679\n",
      "Epoch 00022: loss improved from 1534787.25000 to 1513944.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 1513944.7500 - mae: 919.1752\n",
      "Epoch 23/100\n",
      "2539/2552 [============================>.] - ETA: 0s - loss: 1491782.8750 - mae: 915.0817\n",
      "Epoch 00023: loss improved from 1513944.75000 to 1493166.12500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 13s 5ms/step - loss: 1493166.1250 - mae: 915.3128\n",
      "Epoch 24/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 1472524.7500 - mae: 909.0888\n",
      "Epoch 00024: loss improved from 1493166.12500 to 1472346.00000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 12s 5ms/step - loss: 1472346.0000 - mae: 909.1796\n",
      "Epoch 25/100\n",
      "2540/2552 [============================>.] - ETA: 0s - loss: 1452508.3750 - mae: 900.2084- ETA: 2s \n",
      "Epoch 00025: loss improved from 1472346.00000 to 1452702.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1452702.7500 - mae: 900.3022\n",
      "Epoch 26/100\n",
      "2546/2552 [============================>.] - ETA: 0s - loss: 1434508.0000 - mae: 896.6483\n",
      "Epoch 00026: loss improved from 1452702.75000 to 1434607.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 1434607.7500 - mae: 896.6282\n",
      "Epoch 27/100\n",
      "2550/2552 [============================>.] - ETA: 0s - loss: 1417266.1250 - mae: 890.4708\n",
      "Epoch 00027: loss improved from 1434607.75000 to 1417270.37500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1417270.3750 - mae: 890.4797\n",
      "Epoch 28/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 1399834.8750 - mae: 885.0024- ETA: 1s - loss:\n",
      "Epoch 00028: loss improved from 1417270.37500 to 1398794.62500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 1398794.6250 - mae: 884.6722\n",
      "Epoch 29/100\n",
      "2539/2552 [============================>.] - ETA: 0s - loss: 1387656.1250 - mae: 881.0748\n",
      "Epoch 00029: loss improved from 1398794.62500 to 1387071.25000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 12s 5ms/step - loss: 1387071.2500 - mae: 880.9235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "2542/2552 [============================>.] - ETA: 0s - loss: 1366395.5000 - mae: 875.2720\n",
      "Epoch 00030: loss improved from 1387071.25000 to 1368801.37500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1368801.3750 - mae: 875.5853\n",
      "Epoch 31/100\n",
      "2542/2552 [============================>.] - ETA: 0s - loss: 1351835.6250 - mae: 870.0342\n",
      "Epoch 00031: loss improved from 1368801.37500 to 1352429.12500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 1352429.1250 - mae: 870.1173\n",
      "Epoch 32/100\n",
      "2545/2552 [============================>.] - ETA: 0s - loss: 1331265.5000 - mae: 864.1417\n",
      "Epoch 00032: loss improved from 1352429.12500 to 1330876.12500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 1330876.1250 - mae: 864.0894\n",
      "Epoch 33/100\n",
      "2541/2552 [============================>.] - ETA: 0s - loss: 1307981.6250 - mae: 856.2114\n",
      "Epoch 00033: loss improved from 1330876.12500 to 1308181.12500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1308181.1250 - mae: 856.1385\n",
      "Epoch 34/100\n",
      "2552/2552 [==============================] - ETA: 0s - loss: 1298352.7500 - mae: 851.4621\n",
      "Epoch 00034: loss improved from 1308181.12500 to 1298352.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1298352.7500 - mae: 851.4621\n",
      "Epoch 35/100\n",
      "2550/2552 [============================>.] - ETA: 0s - loss: 1269250.3750 - mae: 841.0198\n",
      "Epoch 00035: loss improved from 1298352.75000 to 1269230.50000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1269230.5000 - mae: 841.0281\n",
      "Epoch 36/100\n",
      "2545/2552 [============================>.] - ETA: 0s - loss: 1263824.1250 - mae: 837.2714\n",
      "Epoch 00036: loss improved from 1269230.50000 to 1263734.37500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1263734.3750 - mae: 837.2749\n",
      "Epoch 37/100\n",
      "2538/2552 [============================>.] - ETA: 0s - loss: 1242985.6250 - mae: 829.1696\n",
      "Epoch 00037: loss improved from 1263734.37500 to 1242346.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1242346.7500 - mae: 829.1290\n",
      "Epoch 38/100\n",
      "2549/2552 [============================>.] - ETA: 0s - loss: 1223625.3750 - mae: 822.5372\n",
      "Epoch 00038: loss improved from 1242346.75000 to 1223641.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1223641.7500 - mae: 822.5602\n",
      "Epoch 39/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 1205673.1250 - mae: 814.7977\n",
      "Epoch 00039: loss improved from 1223641.75000 to 1205983.37500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1205983.3750 - mae: 814.9469\n",
      "Epoch 40/100\n",
      "2546/2552 [============================>.] - ETA: 0s - loss: 1209673.3750 - mae: 815.8316\n",
      "Epoch 00040: loss did not improve from 1205983.37500\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1208755.7500 - mae: 815.4963\n",
      "Epoch 41/100\n",
      "2549/2552 [============================>.] - ETA: 0s - loss: 1188338.6250 - mae: 806.2621\n",
      "Epoch 00041: loss improved from 1205983.37500 to 1188014.12500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 1188014.1250 - mae: 806.1863\n",
      "Epoch 42/100\n",
      "2548/2552 [============================>.] - ETA: 0s - loss: 1176731.0000 - mae: 802.9692\n",
      "Epoch 00042: loss improved from 1188014.12500 to 1176672.25000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1176672.2500 - mae: 802.9474\n",
      "Epoch 43/100\n",
      "2549/2552 [============================>.] - ETA: 0s - loss: 1166198.6250 - mae: 798.9543\n",
      "Epoch 00043: loss improved from 1176672.25000 to 1165780.50000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 1165780.5000 - mae: 798.7684\n",
      "Epoch 44/100\n",
      "2545/2552 [============================>.] - ETA: 0s - loss: 1161440.7500 - mae: 795.8032\n",
      "Epoch 00044: loss improved from 1165780.50000 to 1161539.50000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 1161539.5000 - mae: 795.8260\n",
      "Epoch 45/100\n",
      "2540/2552 [============================>.] - ETA: 0s - loss: 1150973.7500 - mae: 790.2800\n",
      "Epoch 00045: loss improved from 1161539.50000 to 1151284.12500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1151284.1250 - mae: 790.1738\n",
      "Epoch 46/100\n",
      "2551/2552 [============================>.] - ETA: 0s - loss: 1141699.6250 - mae: 786.2858\n",
      "Epoch 00046: loss improved from 1151284.12500 to 1141625.00000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1141625.0000 - mae: 786.2644\n",
      "Epoch 47/100\n",
      "2541/2552 [============================>.] - ETA: 0s - loss: 1138508.3750 - mae: 786.5292\n",
      "Epoch 00047: loss improved from 1141625.00000 to 1140016.00000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1140016.0000 - mae: 786.7607\n",
      "Epoch 48/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 1124768.2500 - mae: 780.0230\n",
      "Epoch 00048: loss improved from 1140016.00000 to 1126286.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1126286.7500 - mae: 780.4176\n",
      "Epoch 49/100\n",
      "2550/2552 [============================>.] - ETA: 0s - loss: 1127812.2500 - mae: 779.5558\n",
      "Epoch 00049: loss did not improve from 1126286.75000\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 1127739.5000 - mae: 779.5706\n",
      "Epoch 50/100\n",
      "2550/2552 [============================>.] - ETA: 0s - loss: 1109700.0000 - mae: 773.3762\n",
      "Epoch 00050: loss improved from 1126286.75000 to 1109471.00000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 1109471.0000 - mae: 773.3025\n",
      "Epoch 51/100\n",
      "2550/2552 [============================>.] - ETA: 0s - loss: 1103416.7500 - mae: 770.4504\n",
      "Epoch 00051: loss improved from 1109471.00000 to 1103437.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1103437.7500 - mae: 770.4723\n",
      "Epoch 52/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 1096162.0000 - mae: 767.2910\n",
      "Epoch 00052: loss improved from 1103437.75000 to 1096839.50000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 1096839.5000 - mae: 767.5295\n",
      "Epoch 53/100\n",
      "2540/2552 [============================>.] - ETA: 0s - loss: 1093236.1250 - mae: 764.8068\n",
      "Epoch 00053: loss improved from 1096839.50000 to 1093824.87500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1093824.8750 - mae: 764.7787\n",
      "Epoch 54/100\n",
      "2542/2552 [============================>.] - ETA: 0s - loss: 1086563.6250 - mae: 761.1328\n",
      "Epoch 00054: loss improved from 1093824.87500 to 1086320.50000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1086320.5000 - mae: 761.0954\n",
      "Epoch 55/100\n",
      "2544/2552 [============================>.] - ETA: 0s - loss: 1076824.1250 - mae: 757.9460\n",
      "Epoch 00055: loss improved from 1086320.50000 to 1077286.37500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 12s 5ms/step - loss: 1077286.3750 - mae: 758.1149\n",
      "Epoch 56/100\n",
      "2550/2552 [============================>.] - ETA: 0s - loss: 1070035.3750 - mae: 754.1945\n",
      "Epoch 00056: loss improved from 1077286.37500 to 1069874.62500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1069874.6250 - mae: 754.1154\n",
      "Epoch 57/100\n",
      "2544/2552 [============================>.] - ETA: 0s - loss: 1059854.6250 - mae: 752.3726\n",
      "Epoch 00057: loss improved from 1069874.62500 to 1060646.00000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1060646.0000 - mae: 752.4837\n",
      "Epoch 58/100\n",
      "2551/2552 [============================>.] - ETA: 0s - loss: 1052576.1250 - mae: 748.6938\n",
      "Epoch 00058: loss improved from 1060646.00000 to 1053798.37500, saving model to model_3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2552/2552 [==============================] - 13s 5ms/step - loss: 1053798.3750 - mae: 748.8514\n",
      "Epoch 59/100\n",
      "2540/2552 [============================>.] - ETA: 0s - loss: 1054185.7500 - mae: 750.2156\n",
      "Epoch 00059: loss did not improve from 1053798.37500\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1054668.7500 - mae: 750.4318\n",
      "Epoch 60/100\n",
      "2549/2552 [============================>.] - ETA: 0s - loss: 1047672.5000 - mae: 745.2038\n",
      "Epoch 00060: loss improved from 1053798.37500 to 1047679.25000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1047679.2500 - mae: 745.2357\n",
      "Epoch 61/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 1041059.7500 - mae: 742.6868\n",
      "Epoch 00061: loss improved from 1047679.25000 to 1040776.68750, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1040776.6875 - mae: 742.7044\n",
      "Epoch 62/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 1036917.5000 - mae: 740.1493\n",
      "Epoch 00062: loss improved from 1040776.68750 to 1037032.68750, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1037032.6875 - mae: 740.1541\n",
      "Epoch 63/100\n",
      "2546/2552 [============================>.] - ETA: 0s - loss: 1025866.1250 - mae: 739.1154\n",
      "Epoch 00063: loss improved from 1037032.68750 to 1025277.81250, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1025277.8125 - mae: 738.8874\n",
      "Epoch 64/100\n",
      "2541/2552 [============================>.] - ETA: 0s - loss: 1021776.6875 - mae: 736.1193\n",
      "Epoch 00064: loss improved from 1025277.81250 to 1021613.31250, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1021613.3125 - mae: 736.0206\n",
      "Epoch 65/100\n",
      "2543/2552 [============================>.] - ETA: 0s - loss: 1010935.5000 - mae: 730.4044\n",
      "Epoch 00065: loss improved from 1021613.31250 to 1011217.50000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1011217.5000 - mae: 730.3122\n",
      "Epoch 66/100\n",
      "2535/2552 [============================>.] - ETA: 0s - loss: 1011564.0000 - mae: 733.9246\n",
      "Epoch 00066: loss improved from 1011217.50000 to 1010090.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 1010090.7500 - mae: 733.5161\n",
      "Epoch 67/100\n",
      "2543/2552 [============================>.] - ETA: 0s - loss: 1004567.1875 - mae: 728.4116\n",
      "Epoch 00067: loss improved from 1010090.75000 to 1004269.93750, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 1004269.9375 - mae: 728.2534\n",
      "Epoch 68/100\n",
      "2552/2552 [==============================] - ETA: 0s - loss: 995706.5000 - mae: 723.7365\n",
      "Epoch 00068: loss improved from 1004269.93750 to 995706.50000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 995706.5000 - mae: 723.7365\n",
      "Epoch 69/100\n",
      "2540/2552 [============================>.] - ETA: 0s - loss: 992690.8125 - mae: 722.8837\n",
      "Epoch 00069: loss improved from 995706.50000 to 993808.00000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 993808.0000 - mae: 723.2138\n",
      "Epoch 70/100\n",
      "2548/2552 [============================>.] - ETA: 0s - loss: 990446.5625 - mae: 720.3085\n",
      "Epoch 00070: loss improved from 993808.00000 to 990352.50000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 990352.5000 - mae: 720.3219\n",
      "Epoch 71/100\n",
      "2552/2552 [==============================] - ETA: 0s - loss: 989111.8750 - mae: 721.4127\n",
      "Epoch 00071: loss improved from 990352.50000 to 989111.87500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 989111.8750 - mae: 721.4127\n",
      "Epoch 72/100\n",
      "2542/2552 [============================>.] - ETA: 0s - loss: 980853.3750 - mae: 717.5365\n",
      "Epoch 00072: loss improved from 989111.87500 to 980207.06250, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 980207.0625 - mae: 717.3441\n",
      "Epoch 73/100\n",
      "2549/2552 [============================>.] - ETA: 0s - loss: 971658.1875 - mae: 713.9323\n",
      "Epoch 00073: loss improved from 980207.06250 to 971432.06250, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 971432.0625 - mae: 713.8917\n",
      "Epoch 74/100\n",
      "2551/2552 [============================>.] - ETA: 0s - loss: 965236.6250 - mae: 712.1799\n",
      "Epoch 00074: loss improved from 971432.06250 to 965321.62500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 965321.6250 - mae: 712.2152\n",
      "Epoch 75/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 953962.1250 - mae: 707.6484\n",
      "Epoch 00075: loss improved from 965321.62500 to 954742.62500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 954742.6250 - mae: 707.8156\n",
      "Epoch 76/100\n",
      "2543/2552 [============================>.] - ETA: 0s - loss: 964630.8125 - mae: 712.2880\n",
      "Epoch 00076: loss did not improve from 954742.62500\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 964512.7500 - mae: 712.3785\n",
      "Epoch 77/100\n",
      "2552/2552 [==============================] - ETA: 0s - loss: 943704.1250 - mae: 705.7590\n",
      "Epoch 00077: loss improved from 954742.62500 to 943704.12500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 943704.1250 - mae: 705.7590\n",
      "Epoch 78/100\n",
      "2546/2552 [============================>.] - ETA: 0s - loss: 931086.4375 - mae: 700.0569\n",
      "Epoch 00078: loss improved from 943704.12500 to 930849.06250, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 930849.0625 - mae: 700.0526\n",
      "Epoch 79/100\n",
      "2543/2552 [============================>.] - ETA: 0s - loss: 927780.8125 - mae: 698.7142\n",
      "Epoch 00079: loss improved from 930849.06250 to 926801.00000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 926801.0000 - mae: 698.2727\n",
      "Epoch 80/100\n",
      "2544/2552 [============================>.] - ETA: 0s - loss: 918589.1875 - mae: 695.8504\n",
      "Epoch 00080: loss improved from 926801.00000 to 918904.68750, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 918904.6875 - mae: 695.9553\n",
      "Epoch 81/100\n",
      "2548/2552 [============================>.] - ETA: 0s - loss: 902070.3750 - mae: 689.2742\n",
      "Epoch 00081: loss improved from 918904.68750 to 903167.87500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 903167.8750 - mae: 689.4056\n",
      "Epoch 82/100\n",
      "2544/2552 [============================>.] - ETA: 0s - loss: 903235.8125 - mae: 690.7931\n",
      "Epoch 00082: loss improved from 903167.87500 to 902654.87500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 902654.8750 - mae: 690.5665\n",
      "Epoch 83/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 892920.1250 - mae: 684.4944\n",
      "Epoch 00083: loss improved from 902654.87500 to 892742.31250, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 892742.3125 - mae: 684.4318\n",
      "Epoch 84/100\n",
      "2546/2552 [============================>.] - ETA: 0s - loss: 875765.8750 - mae: 680.0689\n",
      "Epoch 00084: loss improved from 892742.31250 to 875869.93750, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 875869.9375 - mae: 680.1700\n",
      "Epoch 85/100\n",
      "2544/2552 [============================>.] - ETA: 0s - loss: 882281.7500 - mae: 681.9944\n",
      "Epoch 00085: loss did not improve from 875869.93750\n",
      "2552/2552 [==============================] - 9s 3ms/step - loss: 882246.5000 - mae: 681.9955\n",
      "Epoch 86/100\n",
      "2545/2552 [============================>.] - ETA: 0s - loss: 866960.0000 - mae: 674.7992\n",
      "Epoch 00086: loss improved from 875869.93750 to 866965.43750, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 12s 5ms/step - loss: 866965.4375 - mae: 674.7831\n",
      "Epoch 87/100\n",
      "2549/2552 [============================>.] - ETA: 0s - loss: 858248.1875 - mae: 671.3909\n",
      "Epoch 00087: loss improved from 866965.43750 to 857981.43750, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 857981.4375 - mae: 671.3152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 849647.5000 - mae: 668.4875\n",
      "Epoch 00088: loss improved from 857981.43750 to 850165.62500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 850165.6250 - mae: 668.6979\n",
      "Epoch 89/100\n",
      "2542/2552 [============================>.] - ETA: 0s - loss: 845742.5625 - mae: 666.8588\n",
      "Epoch 00089: loss improved from 850165.62500 to 846068.06250, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 846068.0625 - mae: 666.9547\n",
      "Epoch 90/100\n",
      "2552/2552 [==============================] - ETA: 0s - loss: 837413.7500 - mae: 662.7102\n",
      "Epoch 00090: loss improved from 846068.06250 to 837413.75000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 837413.7500 - mae: 662.7102\n",
      "Epoch 91/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 830736.6875 - mae: 661.2625\n",
      "Epoch 00091: loss improved from 837413.75000 to 830738.87500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 830738.8750 - mae: 661.2767\n",
      "Epoch 92/100\n",
      "2537/2552 [============================>.] - ETA: 0s - loss: 826552.1875 - mae: 660.1632\n",
      "Epoch 00092: loss improved from 830738.87500 to 827167.00000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 827167.0000 - mae: 660.5782\n",
      "Epoch 93/100\n",
      "2542/2552 [============================>.] - ETA: 0s - loss: 819908.3125 - mae: 656.0821\n",
      "Epoch 00093: loss improved from 827167.00000 to 820264.93750, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 820264.9375 - mae: 656.2181\n",
      "Epoch 94/100\n",
      "2550/2552 [============================>.] - ETA: 0s - loss: 811770.4375 - mae: 652.4093\n",
      "Epoch 00094: loss improved from 820264.93750 to 811653.00000, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 811653.0000 - mae: 652.3714\n",
      "Epoch 95/100\n",
      "2548/2552 [============================>.] - ETA: 0s - loss: 806389.3125 - mae: 650.5278\n",
      "Epoch 00095: loss improved from 811653.00000 to 807062.68750, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 807062.6875 - mae: 650.7505\n",
      "Epoch 96/100\n",
      "2548/2552 [============================>.] - ETA: 0s - loss: 801897.1250 - mae: 649.7686\n",
      "Epoch 00096: loss improved from 807062.68750 to 802232.81250, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 11s 4ms/step - loss: 802232.8125 - mae: 649.8518\n",
      "Epoch 97/100\n",
      "2551/2552 [============================>.] - ETA: 0s - loss: 790908.3750 - mae: 644.1940\n",
      "Epoch 00097: loss improved from 802232.81250 to 790892.37500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 790892.3750 - mae: 644.1969\n",
      "Epoch 98/100\n",
      "2547/2552 [============================>.] - ETA: 0s - loss: 793452.4375 - mae: 644.5038\n",
      "Epoch 00098: loss did not improve from 790892.37500\n",
      "2552/2552 [==============================] - 10s 4ms/step - loss: 793204.2500 - mae: 644.4279\n",
      "Epoch 99/100\n",
      "2548/2552 [============================>.] - ETA: 0s - loss: 788522.9375 - mae: 641.4167\n",
      "Epoch 00099: loss improved from 790892.37500 to 788237.12500, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 3ms/step - loss: 788237.1250 - mae: 641.3372\n",
      "Epoch 100/100\n",
      "2544/2552 [============================>.] - ETA: 0s - loss: 786583.9375 - mae: 642.7940\n",
      "Epoch 00100: loss improved from 788237.12500 to 786381.56250, saving model to model_3.h5\n",
      "2552/2552 [==============================] - 9s 4ms/step - loss: 786381.5625 - mae: 642.7022\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(x_train,y_train,epochs=100,batch_size=20,verbose=1,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_1 = load_model('model_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874.4867336424072"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
